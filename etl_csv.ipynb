{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T15:09:01.502959Z",
     "start_time": "2023-07-14T15:08:55.780691Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "rway_img_df_ok = pd.read_csv(\"collection_images_download.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T15:09:03.283717Z",
     "start_time": "2023-07-14T15:09:01.510590Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rway_img_df = rway_img_df_ok.copy()\n",
    "\n",
    "# EXTRACT BRAND FROM IMAGE NAME\n",
    "# Creazione delle nuove colonne\n",
    "rway_img_df['brand'] = rway_img_df['image_name'].str.lower()\n",
    "rway_img_df['brand'] = rway_img_df['brand'].str.split('couture').str[0]\n",
    "rway_img_df['brand'] = rway_img_df['brand'].str.split('ready-to-wear').str[0]\n",
    "rway_img_df['brand'] = rway_img_df['brand'].str.split('menswear').str[0]\n",
    "rway_img_df['brand'] = rway_img_df['brand'].str.replace(\"-\", \" \")\n",
    "rway_img_df['brand'] = rway_img_df['brand'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a small dataframe with the brand in scope\n",
    "brand_in_scope = ['versace', 'hermes']\n",
    "rway_img_df_small = pd.DataFrame()\n",
    "\n",
    "for i,row in enumerate(rway_img_df['brand']):\n",
    "    if row in brand_in_scope:\n",
    "        rway_img_df_small = rway_img_df_small.append(rway_img_df.iloc[i])\n",
    "        \n",
    "rway_img_df_small['image_path_no_bkgnd'] = rway_img_df_small['image_path'].astype(str)\n",
    "\n",
    "# Execute \n",
    "# for each row in rway_img_df_small['image_path_no_bkgnd'] change the output path\n",
    "for index, row in rway_img_df_small.iterrows():\n",
    "    # Split the image path into base name and extension\n",
    "    base_name, extension = row['image_path_no_bkgnd'].split('.')\n",
    "\n",
    "    # Add \"-no-bkgnd\" to the base name\n",
    "    new_base_name = f\"{base_name}-no-bkgnd\"\n",
    "\n",
    "    # Concatenate the new base name with the extension\n",
    "    new_image_path = f\"{new_base_name}.{extension}\"\n",
    "\n",
    "    # Replace the original image path with the new image path\n",
    "    rway_img_df_small.at[index, 'image_path_no_bkgnd'] = new_image_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from rembg import remove\\nimport os\\n\\npath_prefix = \"./imgs/images/images/\"\\n\\n# Assuming rway_img_df_small is a pandas DataFrame containing the image paths\\n# with a column named \\'image_path_no_bkgnd\\'\\n\\nfor index, row in rway_img_df_small.iterrows():\\n    input_path = f\"{path_prefix}{row[\\'image_path\\']}\"\\n    output_path = f\"{path_prefix}{row[\\'image_path_no_bkgnd\\']}\"\\n\\n    with open(input_path, \\'rb\\') as i:\\n        with open(output_path, \\'wb\\') as o:\\n            input_data = i.read()\\n            output_data = remove(input_data)\\n            o.write(output_data)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#! it's takes 105m for 1694 imgs (% of full sample size)\n",
    "#! Time estimate per img 2secs\n",
    "\n",
    "\"\"\"from rembg import remove\n",
    "import os\n",
    "\n",
    "path_prefix = \"./imgs/images/images/\"\n",
    "\n",
    "# Assuming rway_img_df_small is a pandas DataFrame containing the image paths\n",
    "# with a column named 'image_path_no_bkgnd'\n",
    "\n",
    "for index, row in rway_img_df_small.iterrows():\n",
    "    input_path = f\"{path_prefix}{row['image_path']}\"\n",
    "    output_path = f\"{path_prefix}{row['image_path_no_bkgnd']}\"\n",
    "\n",
    "    with open(input_path, 'rb') as i:\n",
    "        with open(output_path, 'wb') as o:\n",
    "            input_data = i.read()\n",
    "            output_data = remove(input_data)\n",
    "            o.write(output_data)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from small dataframe create train (90%) and test (10%) set\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(rway_img_df_small, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(rway_img_df_small['image_path_no_bkgnd'], rway_img_df_small['brand'], test_size=0.2, random_state=1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "959    hermes-menswear-fall-winter-2023-paris/Hermes-...\n",
       "Name: image_path_no_bkgnd, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import cv2\\nimport numpy as np\\n\\noutput_image = cv2.imread(output_path)\\n\\n# Resize the image to 260x260 pixels\\nresized_image = cv2.resize(output_image, (260, 260))\\n\\n# Display the final resized image with a white background\\ncv2.imshow('Resized Image with White Background', resized_image)\\ncv2.waitKey(0)\\ncv2.destroyAllWindows()\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import cv2\n",
    "import numpy as np\n",
    "\n",
    "output_image = cv2.imread(output_path)\n",
    "\n",
    "# Resize the image to 260x260 pixels\n",
    "resized_image = cv2.resize(output_image, (260, 260))\n",
    "\n",
    "# Display the final resized image with a white background\n",
    "cv2.imshow('Resized Image with White Background', resized_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Multiply\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Multiply, Input\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the image data and labels\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(rway_img_df_small['image_path_no_bkgnd'], rway_img_df_small['brand'], test_size=0.2, random_state=1234)\n",
    "\n",
    "# Define image and label dimensions (img_height and img_width) to resize the images during preprocessing.\n",
    "img_height, img_width = 224, 224\n",
    "\n",
    "#Map the brand labels in y_train and y_val to their corresponding integer labels using the brand_to_label dictionary.\n",
    "brand_to_label = {brand: i for i, brand in enumerate(np.unique(rway_img_df_small['brand']))}\n",
    "\n",
    "# Map brand labels to integer labels\n",
    "y_train = np.array([brand_to_label[brand] for brand in y_train])\n",
    "y_val = np.array([brand_to_label[brand] for brand in y_val])\n",
    "\n",
    "# Calculate the number of classes (num_classes) based on the unique labels.\n",
    "num_classes = len(brand_to_label)\n",
    "\n",
    "# Define the preprocess_image function to load, resize, and normalize the pixel values of the images.\n",
    "def preprocess_image(image_path):\n",
    "    image_path = './imgs/images/images/' + image_path  # Add the path prefix\n",
    "    image = load_img(image_path, target_size=(img_height, img_width))\n",
    "    image = img_to_array(image)\n",
    "    image = image / 255.0  # Normalize pixel values between 0 and 1\n",
    "    return image\n",
    "\n",
    "#Preprocess the images in X_train and X_val by applying the preprocess_image function to each image path.\n",
    "X_train = np.array([preprocess_image(path) for path in X_train])\n",
    "# Convert the integer labels in y_train and y_val to one-hot encoded vectors using tf.keras.utils.to_categorical.\n",
    "X_val = np.array([preprocess_image(path) for path in X_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'your_dataframe.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Load the image data and labels\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m rway_img_df_small \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39myour_dataframe.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)  \u001b[39m# Replace with the actual path to your dataframe\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# Split the data into training and validation sets\u001b[39;00m\n\u001b[1;32m      5\u001b[0m X_train, X_val, y_train, y_val \u001b[39m=\u001b[39m train_test_split(rway_img_df_small[\u001b[39m'\u001b[39m\u001b[39mimage_path_no_bkgnd\u001b[39m\u001b[39m'\u001b[39m], rway_img_df_small[\u001b[39m'\u001b[39m\u001b[39mbrand\u001b[39m\u001b[39m'\u001b[39m], test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m1234\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'your_dataframe.csv'"
     ]
    }
   ],
   "source": [
    "# Convert labels to one-hot encoded vectors\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes=num_classes)\n",
    "\n",
    "# Load the VGG16 model without the top classification layer\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(img_height, img_width, 3)))\n",
    "\n",
    "# Add attention mechanism\n",
    "attention = Dense(1, activation='tanh')(base_model.output)\n",
    "attention = GlobalAveragePooling2D()(attention)\n",
    "attention = Multiply()([base_model.output, attention])\n",
    "\n",
    "# Add the top classification layer by applying a dense layer with a tanh activation function, followed by global average pooling and element-wise multiplication.\n",
    "output = GlobalAveragePooling2D()(attention)\n",
    "# Use global average pooling and a dense layer with softmax activation for multi-class classification.\n",
    "output = Dense(num_classes, activation='softmax')(output)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=5, batch_size=32)\n",
    "\n",
    "# Save the trained model\n",
    "model.save('./image_classification_model.h5')  # Replace with your desired path and filename\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
